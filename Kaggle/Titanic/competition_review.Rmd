---
title: "Review on 'Titanic' Kaggle Competition"
author: "Adilet Absatov"
date: 'June 28, 2018'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Competition description

Titanic - один из самых популярных соревнований на Kaggle для начинающих data scientist-ов. Он прост небольшим количеством данных - 891 объект на 11 независымых против одной зависимой - и ясной, но жутковатой задачей - определить, кто из пассажиров печальноизвестного Титаника останется в живых, а кто нет.

## Data engineering

После считывания данных сразу же были удалены 5 независимых переменных - id, имя, номер билета, номер кабины и город посадки на корабль не имеют никакого влияния на фактор выживания.

Так же переменная, описывающая класс каюты, была переведена в факторную.

Пропущенные значения содержались только в переменной "Возраст", поэтому, ввиду ненормального распредения возрастов, они были заменены на медиану ряда.

![](hist.jpg)

![](shapiro.jpg)

## Process

### Linear Model for binomial regression

Реализация:

![](code_glm.jpg)

С помощью линейной модели были определены **вероятности**, что пассажир выживет. Вектор вероятностей сохранен в *prob*. Далее методом подбора был определён порог вероятности, для которого результат был наиболее точным.

То есть, сказав, что при вероятности успеха более 67% пассажир выживет, был получен наилучший результат с использованием линейной модели - 5452 из 11262 место и точность прогноза 78%.

![](glm_position.jpg)

### Decision tree - rpart

Реализация дерева решений была самой простой и короткой, а самое главное - самой эффективной! Кроме того, не требовалась замена пропущенных значений.

![](code_dt.jpg)

Результат - 2500 место с точностью прогноза 79.4%.

![](dt_position.jpg)

### RandomForest

Реализация:

![](code_rf.jpg)

Количество деревьев - 300 определено подбором и кроссвалидацией. Стоит так же отметить, что для построения модели для прогнозирования бинарной факторной переменной используется параметр type = 'classification', а не 'regression'.

Результат был хуже - 77% точности.

![](rf_position.jpg)

### xgboost

Здесь, в следствие того, что xgboost работает только с количественными переменными, факторные столбцы были переведены в числовые.

Реализация: 

![](code_xgb.jpg)

Важно отметить 3 момента:

* Тип модели - логистическая для бинарной классификации: **objective = 'binary:logistic'**
* Показатель оценки - зона под кривой: **eval_metric = 'auc'**
* В качестве результата сначала были получены вероятности, что пассажир выживет, а затем подбором определен порог вероятности для лучшего результата - 0.9.

Результат, однако, был хуже всех остальных - 75% точности (скрин не сохранился).

## Summary

Этот датасет был для меня самым простым и интересным. Очень понравилась реализация дерева решений, оказавшаяся самой эффективной. Итоги точности прогнозов по каждой модели выглядят следующим образом:

* Decision tree - 79.4%
* Linear model - 78%
* RandomForest - 77%
* xgboost - 75%

*Бонус: при разделении "женщины выживыют - мужчины погибают" точность прогноза 76.5%!*